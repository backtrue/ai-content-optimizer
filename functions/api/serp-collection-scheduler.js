/**
 * SERP Collection Scheduler Durable Object
 * ç®¡ç† SERP è’é›†ä»»å‹™çš„æ‰¹æ¬¡åŸ·è¡Œèˆ‡é€²åº¦è¿½è¹¤
 */

export class SerpCollectionScheduler {
  constructor(state, env) {
    this.state = state
    this.env = env
    this.storage = state.storage
  }

  /**
   * åˆå§‹åŒ–ç‹€æ…‹
   */
  async initialize() {
    const existing = await this.storage.get('serp:collection:state')
    if (!existing) {
      await this.storage.put('serp:collection:state', JSON.stringify({
        status: 'idle',
        currentBatch: null,
        totalBatches: 0,
        processedKeywords: 0,
        totalKeywords: 0,
        recordsCollected: 0,
        failedRecords: 0,
        startedAt: null,
        completedAt: null,
        lastError: null,
        batches: []
      }))
    }
  }

  /**
   * å–å¾—ç›®å‰ç‹€æ…‹
   */
  async getStatus() {
    await this.initialize()
    const state = await this.storage.get('serp:collection:state')
    return JSON.parse(state)
  }

  /**
   * æ›´æ–°ç‹€æ…‹
   */
  async updateStatus(updates) {
    const current = await this.getStatus()
    const updated = { ...current, ...updates }
    await this.storage.put('serp:collection:state', JSON.stringify(updated))
    return updated
  }

  /**
   * å•Ÿå‹• SERP è’é›†ä»»å‹™
   */
  async startCollection(options = {}) {
    const current = await this.getStatus()
    
    // æª¢æŸ¥æ˜¯å¦å·²åœ¨åŸ·è¡Œ
    if (current.status === 'running') {
      return {
        success: false,
        error: 'Collection already running',
        state: current
      }
    }

    const now = new Date().toISOString()
    
    // è§£æé—œéµå­—ä¾†æº
    let keywords = []
    
    if (options.keywordsFile) {
      // å¾ R2 è®€å–é—œéµå­—æª”æ¡ˆ
      keywords = await this.loadKeywordsFromR2(options.keywordsFile)
    } else if (options.keywords && Array.isArray(options.keywords)) {
      keywords = options.keywords
    } else if (options.keywordCount) {
      // å¾ KEYWORD_ANALYTICS KV å–å¾—æœ€æ–°çš„é—œéµå­—
      keywords = await this.fetchKeywordsFromKV(options.keywordCount)
    } else {
      return {
        success: false,
        error: 'No keywords provided',
        state: current
      }
    }

    if (keywords.length === 0) {
      return {
        success: false,
        error: 'No keywords found',
        state: current
      }
    }

    const batchSize = options.batchSize || 10
    const totalBatches = Math.ceil(keywords.length / batchSize)

    await this.updateStatus({
      status: 'running',
      totalKeywords: keywords.length,
      totalBatches: totalBatches,
      processedKeywords: 0,
      recordsCollected: 0,
      failedRecords: 0,
      startedAt: now,
      completedAt: null,
      lastError: null,
      batches: []
    })

    // å„²å­˜é—œéµå­—ä¾›å¾ŒçºŒä½¿ç”¨
    await this.storage.put('serp:collection:keywords', JSON.stringify(keywords))
    await this.storage.put('serp:collection:options', JSON.stringify(options))

    try {
      // é–‹å§‹æ‰¹æ¬¡è™•ç†
      for (let batchIndex = 0; batchIndex < totalBatches; batchIndex++) {
        const batchStart = batchIndex * batchSize
        const batchEnd = Math.min(batchStart + batchSize, keywords.length)
        const batchKeywords = keywords.slice(batchStart, batchEnd)

        console.log(`ğŸ”„ è™•ç†æ‰¹æ¬¡ ${batchIndex + 1}/${totalBatches}`)
        
        const batchResult = await this.processBatch(
          batchKeywords,
          batchIndex + 1,
          totalBatches,
          options
        )

        // æ›´æ–°é€²åº¦
        const state = await this.getStatus()
        state.batches.push(batchResult)
        state.processedKeywords += batchKeywords.length
        state.recordsCollected += batchResult.recordsCollected || 0
        state.failedRecords += batchResult.failedRecords || 0
        state.currentBatch = batchIndex + 1

        await this.storage.put('serp:collection:state', JSON.stringify(state))
      }

      // å®Œæˆ
      const finalState = await this.updateStatus({
        status: 'completed',
        completedAt: new Date().toISOString()
      })

      console.log('âœ… SERP è’é›†å®Œæˆ')
      return {
        success: true,
        state: finalState
      }
    } catch (error) {
      console.error('âŒ SERP è’é›†å¤±æ•—:', error)
      await this.updateStatus({
        status: 'failed',
        lastError: error.message,
        completedAt: new Date().toISOString()
      })

      return {
        success: false,
        error: error.message,
        state: await this.getStatus()
      }
    }
  }

  /**
   * è™•ç†å–®å€‹æ‰¹æ¬¡
   */
  async processBatch(batchKeywords, batchIndex, totalBatches, options) {
    const analyzeApiUrl = options.analyzeApiUrl || 'https://ragseo.thinkwithblack.com/api/analyze'
    const keywordDelay = options.keywordDelay || 15
    const urlDelay = options.urlDelay || 12

    let recordsCollected = 0
    let failedRecords = 0
    const batchRecords = []

    for (const keyword of batchKeywords) {
      try {
        // å–å¾— SERP çµæœ
        const serpResults = await this.fetchSerpResults(keyword)
        
        if (!serpResults || serpResults.length === 0) {
          console.warn(`âš ï¸ æœªå–å¾— ${keyword} çš„ SERP çµæœ`)
          failedRecords++
          continue
        }

        // åˆ†ææ¯å€‹ URL
        for (let rank = 0; rank < serpResults.length; rank++) {
          const result = serpResults[rank]
          const url = result.link || result.url
          
          try {
            const analysis = await this.analyzeUrl(url, keyword, analyzeApiUrl)
            
            batchRecords.push({
              keyword,
              url,
              title: result.title,
              rank: rank + 1,
              timestamp: new Date().toISOString(),
              analysis
            })
            
            recordsCollected++
            
            // å»¶é²
            await this.sleep(urlDelay * 1000)
          } catch (error) {
            console.error(`âŒ åˆ†æ ${url} å¤±æ•—:`, error)
            failedRecords++
          }
        }

        // é—œéµå­—é–“éš”
        await this.sleep(keywordDelay * 1000)
      } catch (error) {
        console.error(`âŒ è™•ç†é—œéµå­— ${keyword} å¤±æ•—:`, error)
        failedRecords++
      }
    }

    // ä¸Šå‚³æ‰¹æ¬¡çµæœè‡³ R2
    const r2Key = await this.uploadBatchToR2(batchRecords, batchIndex)

    return {
      batchIndex,
      totalBatches,
      keywordCount: batchKeywords.length,
      recordsCollected,
      failedRecords,
      r2Key,
      completedAt: new Date().toISOString()
    }
  }

  /**
   * å–å¾— SERP çµæœ
   */
  async fetchSerpResults(keyword) {
    try {
      // å‘¼å« SERP APIï¼ˆå‡è¨­å·²åœ¨ Worker ä¸­é…ç½®ï¼‰
      const response = await fetch('http://internal/api/serp/fetch', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ keyword })
      })

      if (response.ok) {
        const data = await response.json()
        return data.results || []
      }

      console.warn(`âš ï¸ SERP API å›å‚³ ${response.status}`)
      return []
    } catch (error) {
      console.error(`âŒ SERP è’é›†å¤±æ•—:`, error)
      return []
    }
  }

  /**
   * åˆ†æ URL
   */
  async analyzeUrl(url, keyword, apiUrl) {
    try {
      const response = await fetch(apiUrl, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contentUrl: url,
          targetKeywords: [keyword],
          returnChunks: false
        }),
        timeout: 60000
      })

      if (response.ok) {
        return await response.json()
      }

      throw new Error(`HTTP ${response.status}`)
    } catch (error) {
      console.error(`âŒ åˆ†æå¤±æ•—:`, error)
      return {
        error: error.message,
        status: 'failed'
      }
    }
  }

  /**
   * å¾ R2 è®€å–é—œéµå­—æª”æ¡ˆ
   */
  async loadKeywordsFromR2(r2Key) {
    try {
      if (!this.env.KEYWORD_EXPORTS_BUCKET) {
        throw new Error('R2 bucket æœªè¨­å®š')
      }

      const file = await this.env.KEYWORD_EXPORTS_BUCKET.get(r2Key)
      if (!file) {
        throw new Error(`R2 æª”æ¡ˆä¸å­˜åœ¨: ${r2Key}`)
      }

      const content = await file.text()
      const data = JSON.parse(content)

      if (data.keywords && Array.isArray(data.keywords)) {
        return data.keywords
      }

      return []
    } catch (error) {
      console.error(`âŒ å¾ R2 è®€å–é—œéµå­—å¤±æ•—:`, error)
      return []
    }
  }

  /**
   * å¾ KV å–å¾—é—œéµå­—
   */
  async fetchKeywordsFromKV(limit = 200) {
    try {
      if (!this.env.KEYWORD_ANALYTICS) {
        throw new Error('KEYWORD_ANALYTICS KV æœªè¨­å®š')
      }

      const keywords = []
      let cursor

      do {
        const listResult = await this.env.KEYWORD_ANALYTICS.list({
          prefix: 'kw:',
          limit: 100,
          cursor
        })

        for (const entry of listResult.keys) {
          if (keywords.length >= limit) break

          const raw = await this.env.KEYWORD_ANALYTICS.get(entry.name)
          if (!raw) continue

          try {
            const record = JSON.parse(raw)
            keywords.push(record.keyword)
          } catch (error) {
            console.warn('è§£æ keyword record å¤±æ•—:', entry.name)
          }
        }

        if (keywords.length >= limit || listResult.list_complete) {
          break
        }

        cursor = listResult.cursor
      } while (cursor)

      return keywords
    } catch (error) {
      console.error(`âŒ å¾ KV å–å¾—é—œéµå­—å¤±æ•—:`, error)
      return []
    }
  }

  /**
   * ä¸Šå‚³æ‰¹æ¬¡çµæœè‡³ R2
   */
  async uploadBatchToR2(records, batchIndex) {
    try {
      if (!this.env.KEYWORD_EXPORTS_BUCKET) {
        console.warn('R2 bucket æœªè¨­å®šï¼Œè·³éä¸Šå‚³')
        return null
      }

      const dateStr = new Date().toISOString().split('T')[0]
      const key = `serp-results/${dateStr}/batch-${batchIndex}.json`

      const content = JSON.stringify({
        batchIndex,
        recordCount: records.length,
        records,
        uploadedAt: new Date().toISOString()
      }, null, 2)

      await this.env.KEYWORD_EXPORTS_BUCKET.put(key, content, {
        httpMetadata: {
          contentType: 'application/json'
        }
      })

      console.log(`âœ… æ‰¹æ¬¡çµæœå·²ä¸Šå‚³è‡³ R2: ${key}`)
      return key
    } catch (error) {
      console.error(`âŒ R2 ä¸Šå‚³å¤±æ•—:`, error)
      return null
    }
  }

  /**
   * å»¶é²å‡½æ•¸
   */
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms))
  }

  /**
   * å–æ¶ˆè’é›†
   */
  async cancelCollection() {
    const current = await this.getStatus()
    
    if (current.status !== 'running') {
      throw new Error('Collection is not running')
    }

    await this.updateStatus({
      status: 'cancelled',
      completedAt: new Date().toISOString()
    })

    console.log('âŒ SERP è’é›†å·²å–æ¶ˆ')
    return await this.getStatus()
  }

  /**
   * è™•ç† HTTP è«‹æ±‚
   */
  async fetch(request) {
    const url = new URL(request.url)
    const path = url.pathname
    const method = request.method

    try {
      // GET /serp-collection/status
      if (method === 'GET' && path === '/serp-collection/status') {
        return new Response(JSON.stringify(await this.getStatus()), {
          headers: { 'Content-Type': 'application/json' }
        })
      }

      // POST /serp-collection/start
      if (method === 'POST' && path === '/serp-collection/start') {
        const options = await request.json().catch(() => ({}))
        const result = await this.startCollection(options)
        return new Response(JSON.stringify(result), {
          headers: { 'Content-Type': 'application/json' },
          status: result.success ? 200 : 400
        })
      }

      // POST /serp-collection/cancel
      if (method === 'POST' && path === '/serp-collection/cancel') {
        const result = await this.cancelCollection()
        return new Response(JSON.stringify({ success: true, state: result }), {
          headers: { 'Content-Type': 'application/json' }
        })
      }

      return new Response(JSON.stringify({ error: 'Not found' }), {
        status: 404,
        headers: { 'Content-Type': 'application/json' }
      })
    } catch (error) {
      console.error('SERP Collection è«‹æ±‚è™•ç†å¤±æ•—:', error)
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { 'Content-Type': 'application/json' }
      })
    }
  }
}

export default {
  fetch: (request, env, ctx) => {
    const id = env.SERP_COLLECTION_SCHEDULER.idFromName('default')
    const obj = env.SERP_COLLECTION_SCHEDULER.get(id)
    return obj.fetch(request)
  }
}
