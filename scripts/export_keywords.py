#!/usr/bin/env python3
"""
é—œéµå­—è³‡æ–™åŒ¯å‡ºè…³æœ¬
å¾ Cloudflare KV (KEYWORD_ANALYTICS) åŒ¯å‡ºå»é‡å¾Œçš„é—œéµå­—æ¸…å–®
æ”¯æ´æ™‚é–“ç¯„åœèˆ‡ locale ç¯©é¸
"""

import os
import sys
import json
import argparse
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Set
from pathlib import Path

# å‡è¨­ Cloudflare Workers ç’°å¢ƒè®Šæ•¸å·²è¨­å®š
# æ­¤è…³æœ¬å¯é€é Worker API æˆ–ç›´æ¥ KV å­˜å–


def load_env_variables() -> None:
    """è¼‰å…¥æœ¬åœ°ç’°å¢ƒæª”"""
    candidate_files = ['.env', '.env.local', '.env.example']
    
    for filename in candidate_files:
        if os.path.exists(filename):
            with open(filename, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
                    if '=' not in line:
                        continue
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip()
                    if value and len(value) >= 2 and value[0] == value[-1] and value[0] in ('"', "'"):
                        value = value[1:-1]
                    os.environ[key] = value
            print(f"âœ… å·²è¼‰å…¥ç’°å¢ƒè¨­å®šæª”ï¼š{filename}")
            break


class KeywordExporter:
    """é—œéµå­—åŒ¯å‡ºå™¨"""
    
    def __init__(self, api_url: str, api_token: str):
        """
        åˆå§‹åŒ–åŒ¯å‡ºå™¨
        
        Args:
            api_url: Worker API åŸºç¤ URL (e.g., https://api.example.com)
            api_token: èªè­‰ Token (KEYWORD_ANALYTICS_TOKEN)
        """
        self.api_url = api_url.rstrip('/')
        self.api_token = api_token
        self.keywords_endpoint = f"{self.api_url}/api/keywords/recent"
    
    def fetch_keywords(
        self,
        limit: int = 200,
        since: Optional[str] = None,
        locale: Optional[str] = None
    ) -> List[Dict]:
        """
        å¾ Worker API å–å¾—é—œéµå­—
        
        Args:
            limit: æœ€å¤§ç­†æ•¸
            since: ISO 8601 æ™‚é–“æˆ³ (e.g., "2025-11-10T00:00:00Z")
            locale: èªç³»ç¯©é¸ (e.g., "zh-TW", "en")
        
        Returns:
            é—œéµå­—è¨˜éŒ„æ¸…å–®
        """
        import requests
        
        headers = {
            'Authorization': f'Bearer {self.api_token}',
            'Content-Type': 'application/json'
        }
        
        params = {'limit': limit}
        if since:
            params['since'] = since
        if locale:
            params['locale'] = locale
        
        try:
            response = requests.get(
                self.keywords_endpoint,
                headers=headers,
                params=params,
                timeout=30
            )
            response.raise_for_status()
            data = response.json()
            print(f"âœ… å–å¾— {data.get('count', 0)} ç­†é—œéµå­—è¨˜éŒ„")
            return data.get('records', [])
        except Exception as e:
            print(f"âŒ å–å¾—é—œéµå­—å¤±æ•—: {e}")
            return []
    
    def deduplicate_keywords(self, records: List[Dict]) -> Dict[str, Dict]:
        """
        å»é‡é—œéµå­—ï¼ˆä¿ç•™æœ€æ–°çš„è¨˜éŒ„ï¼‰
        
        Args:
            records: é—œéµå­—è¨˜éŒ„æ¸…å–®
        
        Returns:
            å»é‡å¾Œçš„é—œéµå­—å­—å…¸ {keyword: record}
        """
        deduped = {}
        
        for record in records:
            keyword = record.get('keyword', '').strip()
            if not keyword:
                continue
            
            # ä¿ç•™æœ€æ–°çš„è¨˜éŒ„ï¼ˆæŒ‰ timestamp æ’åºï¼‰
            if keyword not in deduped or record.get('timestamp', '') > deduped[keyword].get('timestamp', ''):
                deduped[keyword] = record
        
        print(f"âœ… å»é‡å®Œæˆï¼š{len(records)} â†’ {len(deduped)} ç­†")
        return deduped
    
    def export_to_json(
        self,
        keywords: Dict[str, Dict],
        output_path: str,
        date_str: Optional[str] = None
    ) -> str:
        """
        åŒ¯å‡ºç‚º JSON æª”æ¡ˆ
        
        Args:
            keywords: å»é‡å¾Œçš„é—œéµå­—å­—å…¸
            output_path: è¼¸å‡ºç›®éŒ„è·¯å¾‘
            date_str: æ—¥æœŸå­—ä¸² (e.g., "2025-11-11")ï¼Œé è¨­ç‚ºä»Šæ—¥
        
        Returns:
            è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        if not date_str:
            date_str = datetime.now().strftime('%Y-%m-%d')
        
        output_dir = Path(output_path)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        filename = f"keywords-{date_str}.json"
        filepath = output_dir / filename
        
        output_data = {
            'exportedAt': datetime.now().isoformat(),
            'dateStr': date_str,
            'count': len(keywords),
            'keywords': list(keywords.keys()),
            'records': list(keywords.values())
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å·²åŒ¯å‡ºè‡³ JSONï¼š{filepath}")
        return str(filepath)
    
    def export_to_csv(
        self,
        keywords: Dict[str, Dict],
        output_path: str,
        date_str: Optional[str] = None
    ) -> str:
        """
        åŒ¯å‡ºç‚º CSV æª”æ¡ˆ
        
        Args:
            keywords: å»é‡å¾Œçš„é—œéµå­—å­—å…¸
            output_path: è¼¸å‡ºç›®éŒ„è·¯å¾‘
            date_str: æ—¥æœŸå­—ä¸²
        
        Returns:
            è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        import csv
        
        if not date_str:
            date_str = datetime.now().strftime('%Y-%m-%d')
        
        output_dir = Path(output_path)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        filename = f"keywords-{date_str}.csv"
        filepath = output_dir / filename
        
        # æº–å‚™ CSV æ¬„ä½
        fieldnames = ['keyword', 'locale', 'timestamp', 'source', 'volume', 'difficulty']
        
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for keyword, record in keywords.items():
                row = {
                    'keyword': keyword,
                    'locale': record.get('locale', ''),
                    'timestamp': record.get('timestamp', ''),
                    'source': record.get('source', ''),
                    'volume': record.get('volume', ''),
                    'difficulty': record.get('difficulty', '')
                }
                writer.writerow(row)
        
        print(f"âœ… å·²åŒ¯å‡ºè‡³ CSVï¼š{filepath}")
        return str(filepath)


def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(
        description='å¾ Cloudflare KV åŒ¯å‡ºå»é‡å¾Œçš„é—œéµå­—æ¸…å–®'
    )
    parser.add_argument(
        '--api-url',
        default=os.getenv('KEYWORD_EXPORT_API_URL', 'http://localhost:8787'),
        help='Worker API åŸºç¤ URL'
    )
    parser.add_argument(
        '--api-token',
        default=os.getenv('KEYWORD_ANALYTICS_TOKEN', ''),
        help='èªè­‰ Token'
    )
    parser.add_argument(
        '--output-dir',
        default='./keywords-export',
        help='è¼¸å‡ºç›®éŒ„'
    )
    parser.add_argument(
        '--limit',
        type=int,
        default=200,
        help='æœ€å¤§ç­†æ•¸'
    )
    parser.add_argument(
        '--since',
        help='æ™‚é–“ç¯„åœèµ·é» (ISO 8601 æ ¼å¼)'
    )
    parser.add_argument(
        '--locale',
        help='èªç³»ç¯©é¸ (e.g., zh-TW, en)'
    )
    parser.add_argument(
        '--format',
        choices=['json', 'csv', 'both'],
        default='both',
        help='åŒ¯å‡ºæ ¼å¼'
    )
    parser.add_argument(
        '--date',
        help='æ—¥æœŸå­—ä¸² (YYYY-MM-DD)ï¼Œé è¨­ç‚ºä»Šæ—¥'
    )
    
    args = parser.parse_args()
    
    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    load_env_variables()
    
    # é©—è­‰å¿…è¦åƒæ•¸
    if not args.api_token:
        print("âŒ éŒ¯èª¤ï¼šKEYWORD_ANALYTICS_TOKEN æœªè¨­å®š")
        sys.exit(1)
    
    # åˆå§‹åŒ–åŒ¯å‡ºå™¨
    exporter = KeywordExporter(args.api_url, args.api_token)
    
    # å–å¾—é—œéµå­—
    print(f"ğŸ“¥ æ­£åœ¨å¾ {args.api_url} å–å¾—é—œéµå­—...")
    records = exporter.fetch_keywords(
        limit=args.limit,
        since=args.since,
        locale=args.locale
    )
    
    if not records:
        print("âš ï¸ æœªå–å¾—ä»»ä½•é—œéµå­—è¨˜éŒ„")
        sys.exit(1)
    
    # å»é‡
    keywords = exporter.deduplicate_keywords(records)
    
    # åŒ¯å‡º
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if args.format in ['json', 'both']:
        exporter.export_to_json(keywords, args.output_dir, args.date)
    
    if args.format in ['csv', 'both']:
        exporter.export_to_csv(keywords, args.output_dir, args.date)
    
    print(f"âœ… åŒ¯å‡ºå®Œæˆï¼š{len(keywords)} ç­†å»é‡å¾Œçš„é—œéµå­—")


if __name__ == '__main__':
    main()
